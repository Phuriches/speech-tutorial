{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tune FLAN-T5 with RL (PPO) and PEFT to generate less-toxic summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification, AutoModelForSeq2SeqLM, GenerationConfig\n",
    "from datasets import load_dataset\n",
    "from peft import PeftModel, PeftConfig, LoraConfig, TaskType\n",
    "\n",
    "# trl: Transofrmer Reinforcement Learning that provides an access to PPO\n",
    "from trl import PPOTrainer, PPOConfig, AutoModelForSeq2SeqLMWithValueHead\n",
    "from trl import create_reference_model\n",
    "from trl.core import LengthSampler \n",
    "\n",
    "import torch\n",
    "import evaluate\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load FLAN-T5 model, prepare Reward model and Toxicity Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (/home/tslab/phusaeng/.cache/huggingface/datasets/knkarthick___csv/knkarthick--dialogsum-c8fac5d84cd35861/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38bd36d517344b71b495b7b002e22c04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'dialogue', 'summary', 'topic'],\n",
       "        num_rows: 12460\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'dialogue', 'summary', 'topic'],\n",
       "        num_rows: 500\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'dialogue', 'summary', 'topic'],\n",
       "        num_rows: 1500\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"google/flan-t5-base\"\n",
    "huggingface_dataset_name = \"knkarthick/dialogsum\"\n",
    "\n",
    "dataset_original = load_dataset(huggingface_dataset_name)\n",
    "dataset_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Person1#: You have the right to remain silent. Anything you say can and will be used against you in a court of law. You have the right to have an attorney present during questioning. If you cannot afford an attorney, one will be appointed for you. Do you understand?\n",
      "#Person2#: Yes.\n",
      "#Person1#: What's your name?\n",
      "#Person2#: My name is James.\n",
      "#Person1#: What's your nationality?\n",
      "#Person2#: American.\n",
      "#Person1#: What's your relationship with the victim?\n",
      "#Person2#: I don't know him.\n",
      "#Person1#: Why did you attack the victim?\n",
      "#Person2#: Because he beat me first when I tried to stop him from grabbing my bag and running away.\n",
      "#Person1#: How many times did you stab the victim?\n",
      "#Person2#: I stabbed his belly three times.\n",
      "#Person1#: Did you know that your actions might cause serous injuries or death?\n",
      "#Person2#: I knew, but I couldn't control myself.\n",
      "#Person1#: Was it your intention to kill the victim?\n",
      "#Person2#: No. I didn't kill him on purpose, madam. It's him who caused the incident. I need to see my attorney.\n",
      "#Person1#: OK. Give me his number and we'll contact him.\n",
      "\n",
      "SUMMARY:\n",
      "\n",
      "#Person1# stabbed the victim because he beat #Person1# first and tried to grab #Person1#'s bag. #Person1# says he didn't kill him on purpose.\n"
     ]
    }
   ],
   "source": [
    "idx = 50\n",
    "print(dataset_original['train']['dialogue'][:50+idx][idx])\n",
    "print('\\nSUMMARY:\\n')\n",
    "print(dataset_original['train']['summary'][:50+idx][idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (/home/tslab/phusaeng/.cache/huggingface/datasets/knkarthick___csv/knkarthick--dialogsum-c8fac5d84cd35861/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88719732e9e5444b978a6dccf223414e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/12460 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "973e8d14a2cf4dd38806e027333c6402",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10022 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'dialogue', 'summary', 'topic', 'input_ids', 'query'],\n",
      "        num_rows: 8017\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'dialogue', 'summary', 'topic', 'input_ids', 'query'],\n",
      "        num_rows: 2005\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# preprocess dataset\n",
    "def build_dataset(model_name, \n",
    "                dataset_name,\n",
    "                input_min_text_length,\n",
    "                input_max_text_length,\n",
    "                filtered_dataset=True):\n",
    "    # load dataset\n",
    "    dataset = load_dataset(dataset_name, split='train')\n",
    "    if filtered_dataset: #filter the dialogues of length between input_min_text_length and input_max_text_length\n",
    "        dataset = dataset.filter(lambda x: len(x['dialogue']) > input_min_text_length and len(x['dialogue']) <= input_max_text_length, batched=False) \n",
    "\n",
    "    # Prepare tokenizer. Setting device_map=\"auto\" allows to switch between CPU and GPU automatically.\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name, device_map=\"auto\")\n",
    "\n",
    "    def tokenize(sample):\n",
    "        prompt = f\"\"\"\n",
    "Summarize the following conversation.\n",
    "\n",
    "{sample['dialogue']}\n",
    "\n",
    "Summary:\n",
    "\"\"\"\n",
    "        sample['input_ids'] = tokenizer.encode(prompt)\n",
    "\n",
    "        # This must be called \"query\", which is a requirement of our PPO library.\n",
    "        sample['query'] = tokenizer.decode(sample['input_ids'])\n",
    "        return sample\n",
    "\n",
    "    # Tokenize each dialogue\n",
    "    dataset = dataset.map(tokenize, batched=False)\n",
    "    dataset.set_format(type='torch')\n",
    "\n",
    "    # split the dataset into train and test.\n",
    "    dataset_splits = dataset.train_test_split(test_size=0.2, shuffle=False, seed=42)\n",
    "\n",
    "    return dataset_splits\n",
    "\n",
    "dataset = build_dataset(model_name=model_name,\n",
    "                        dataset_name=huggingface_dataset_name,\n",
    "                        input_min_text_length=200,\n",
    "                        input_max_text_length=1000)\n",
    "\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to count number of parameters\n",
    "def count_parameters(model):\n",
    "    def num_to_readable_str(num):\n",
    "        return format(num, ',')\n",
    "\n",
    "    trainable_model_params = 0\n",
    "    all_model_params = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_model_params += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_model_params += param.numel()\n",
    "    return f\"\\ntrainable params: {num_to_readable_str(trainable_model_params)}\\nall params: {num_to_readable_str(all_model_params)}\\npercentage of trainable params: {num_to_readable_str(round(100*trainable_model_params/all_model_params, 3))}%\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PEFT model parameters to be updated: \n",
      "\n",
      "trainable params: 3,538,944\n",
      "all params: 251,116,800\n",
      "percentage of trainable params: 1.409%\n"
     ]
    }
   ],
   "source": [
    "# add the adapter to the original FLAN-T5\n",
    "lora_config = LoraConfig(\n",
    "    r=32, # Rank\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"q\", \"v\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.SEQ_2_SEQ_LM # FLAN-T5\n",
    ")\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name, \n",
    "                                              torch_dtype=torch.bfloat16,)\n",
    "\n",
    "peft_path = \"./weights/peft-dialogue-summary-training-1690379059/checkpoint-500\"\n",
    "peft_model = PeftModel.from_pretrained(model, \n",
    "                                       peft_path,\n",
    "                                       config=lora_config,\n",
    "                                       torch_dtype=torch.bfloat16,\n",
    "                                       device_map=\"auto\",\n",
    "                                       is_trainable=True)\n",
    "print(f'PEFT model parameters to be updated: \\n{count_parameters(peft_model)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters to be updated (ValueHead + 769 params):\n",
      "\n",
      "trainable params: 3,539,713\n",
      "all params: 251,117,569\n",
      "percentage of trainable params: 1.41%\n",
      "ValueHead(\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (summary): Linear(in_features=768, out_features=1, bias=True)\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "ppo_model = AutoModelForSeq2SeqLMWithValueHead.from_pretrained(peft_model,\n",
    "                                                               torch_dtype=torch.bfloat16,\n",
    "                                                               is_trainable=True,)\n",
    "print(f'Number of parameters to be updated (ValueHead + 769 params):\\n{count_parameters(ppo_model)}')\n",
    "print(ppo_model.v_head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Referece model parameters to be updated:\n",
      "\n",
      "trainable params: 0\n",
      "all params: 251,117,569\n",
      "percentage of trainable params: 0.0%\n"
     ]
    }
   ],
   "source": [
    "# init ref model for preventing reward hacking\n",
    "ref_model = create_reference_model(ppo_model)\n",
    "\n",
    "print(f'Referece model parameters to be updated:\\n{count_parameters(ref_model)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model weights are not tied. Please use the `tie_weights` method before using the `infer_auto_device` function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'nothate', 1: 'hate'}\n"
     ]
    }
   ],
   "source": [
    "# Prepare reward model (that is representing human preference). In this case, we are trying to detoxify the LLM.\n",
    "# Our reward model will provide the rewards based on the toxicity of the generated text. We use pre-trained sentiment analysis model, \n",
    "# which will classify not hate and hate.\n",
    "toxicity_model_name = 'facebook/roberta-hate-speech-dynabench-r4-target'\n",
    "toxicity_tokenizer = AutoTokenizer.from_pretrained(toxicity_model_name, device_map='auto')\n",
    "toxicity_model = AutoModelForSequenceClassification.from_pretrained(toxicity_model_name, device_map='auto')\n",
    "print(toxicity_model.config.id2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input text: I want to kiss you\n",
      "logits [not hate, hate]: [4.657958030700684, -4.078615188598633]\n",
      "logits prob [not hate, hate]: [0.9998394250869751, 0.000160577503265813]\n",
      "reward: [4.657958030700684]\n"
     ]
    }
   ],
   "source": [
    "# example\n",
    "not_hate_index = 0\n",
    "def example_getting_rewards(text, not_hate_index=0):\n",
    "    print(f'input text: {text}')\n",
    "    non_toxic_text = text\n",
    "    toxicity_input_ids = toxicity_tokenizer.encode(non_toxic_text, return_tensors='pt')\n",
    "    logits = toxicity_model(input_ids=toxicity_input_ids).logits\n",
    "    print(f'logits [not hate, hate]: {logits.tolist()[0]}')\n",
    "    # print probabilities of not hate and hate\n",
    "    probs = torch.softmax(logits, dim=1).tolist()[0]\n",
    "    print(f'logits prob [not hate, hate]: {probs}')\n",
    "    # get the reward for not hate\n",
    "    nothate_reward = (logits[:, not_hate_index]).tolist()\n",
    "    print(f'reward: {nothate_reward}')\n",
    "non_toxic_text = \"I want to kiss you\"\n",
    "toxic_text = \"fuck you damn hate you\"\n",
    "example_getting_rewards(non_toxic_text, not_hate_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input text: fuck you damn hate you\n",
      "logits [not hate, hate]: [-2.2604756355285645, 1.990470051765442]\n",
      "logits prob [not hate, hate]: [0.01405052188783884, 0.9859494566917419]\n",
      "reward: [-2.2604756355285645]\n"
     ]
    }
   ],
   "source": [
    "example_getting_rewards(toxic_text, not_hate_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward model output for non-toxic text:\n",
      "non-toxic text: I want to kiss you\n",
      "[{'label': 'nothate', 'score': 4.657958030700684}, {'label': 'hate', 'score': -4.078615188598633}]\n",
      "[{'label': 'nothate', 'score': 0.9998394250869751}, {'label': 'hate', 'score': 0.00016057751781772822}]\n",
      "Reward model output for toxic text:\n",
      "toxic text: fuck you damn hate you\n",
      "[{'label': 'hate', 'score': 1.990470051765442}, {'label': 'nothate', 'score': -2.2604756355285645}]\n",
      "[{'label': 'hate', 'score': 0.9859494566917419}, {'label': 'nothate', 'score': 0.014050522819161415}]\n"
     ]
    }
   ],
   "source": [
    "# Try to generate reward using pipeline\n",
    "device = 0 if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "sentiment_pipe = pipeline(\"sentiment-analysis\",\n",
    "                          model=toxicity_model,\n",
    "                          tokenizer=toxicity_tokenizer,\n",
    "                          device=device) \n",
    "reward_logits_kwargs = {\n",
    "    \"top_k\": None, # return all scores\n",
    "    \"function_to_apply\": \"none\",  # set to \"none\" to retrieve raw logits\n",
    "    \"batch_size\": 16\n",
    "}\n",
    "reward_probabilities_kwargs = {\n",
    "    \"top_k\": None, # return all scores\n",
    "     \"function_to_apply\": \"softmax\",  # set to \"softmax\" to retrieve probabilities\n",
    "    \"batch_size\": 16\n",
    "}\n",
    "\n",
    "print(\"Reward model output for non-toxic text:\")\n",
    "print(f'non-toxic text: {non_toxic_text}')\n",
    "print(sentiment_pipe(non_toxic_text, **reward_logits_kwargs))\n",
    "print(sentiment_pipe(non_toxic_text, **reward_probabilities_kwargs))\n",
    "print(\"Reward model output for toxic text:\")\n",
    "print(f'toxic text: {toxic_text}')\n",
    "print(sentiment_pipe(toxic_text, **reward_logits_kwargs))\n",
    "print(sentiment_pipe(toxic_text, **reward_probabilities_kwargs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Toxicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dda41d380c9a4af99346e31f12cdf8bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/6.08k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "toxicity_evaluator = evaluate.load(\"toxicity\",\n",
    "                                   toxicity_model_name,\n",
    "                                   module_type=\"measurement\",\n",
    "                                   toxic_label=\"hate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic score for non-toxic text: {'toxicity': [0.00016057751781772822]}\n",
      "toxic score for toxic text: {'toxicity': [0.9859494566917419]}\n"
     ]
    }
   ],
   "source": [
    "# try to calculate toxicity for the same sentences\n",
    "toxicity_score = toxicity_evaluator.compute(predictions=[\n",
    "    non_toxic_text\n",
    "])\n",
    "print(f'toxic score for non-toxic text: {toxicity_score}')\n",
    "\n",
    "toxicity_score = toxicity_evaluator.compute(predictions=[\n",
    "    toxic_text\n",
    "])\n",
    "print(f'toxic score for toxic text: {toxicity_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_toxicity(model,\n",
    "                      toxicity_evaluator,\n",
    "                      tokenizer,\n",
    "                      dataset,\n",
    "                      num_samples):\n",
    "    max_new_tokens = 100\n",
    "\n",
    "    toxicities = []\n",
    "    # input_texts =[]\n",
    "    for i, sample in tqdm(enumerate(dataset)):\n",
    "        input_text = sample['query']\n",
    "\n",
    "        if i > num_samples:\n",
    "            break\n",
    "\n",
    "        input_ids = tokenizer(input_text, return_tensors='pt', padding=True).input_ids.to(device)\n",
    "\n",
    "        generation_config = GenerationConfig(max_new_tokens=max_new_tokens,\n",
    "                                             top_k=0.0,\n",
    "                                             top_p=1.0,\n",
    "                                             do_sample=True)\n",
    "        response_token_ids = model.generate(input_ids=input_ids,\n",
    "                                            generation_config=generation_config,)\n",
    "        generated_text = tokenizer.decode(response_token_ids[0], skip_special_tokens=True)\n",
    "        toxicity_score = toxicity_evaluator.compute(predictions=[input_text + \" \" + generated_text])\n",
    "        toxicities.append(toxicity_score['toxicity'])\n",
    "    print(toxicities)\n",
    "    mean = np.mean(toxicities)\n",
    "    std = np.std(toxicities)\n",
    "    return mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [00:07,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0016826004721224308], [0.06922271847724915], [0.023195229470729828], [0.0024963051546365023], [0.0014516387600451708], [0.017385272309184074], [0.0683618113398552], [0.0051985434256494045], [0.19036133587360382], [0.017040222883224487], [0.013291467912495136]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# perform the calculation of the mdoel toxicity before fine-tuning/detoxification\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, device_map='auto')\n",
    "mean_before_detoxification, std_before_detoxification = evaluate_toxicity(ref_model.to(device), \n",
    "                                                                        toxicity_evaluator=toxicity_evaluator, \n",
    "                                                                        tokenizer=tokenizer, \n",
    "                                                                        dataset=dataset['test'],\n",
    "                                                                        num_samples=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxiciy [mean, std] before detoxification: [0.0372442860071632, 0.053758338404269385]\n"
     ]
    }
   ],
   "source": [
    "print(f'toxiciy [mean, std] before detoxification: [{mean_before_detoxification}, {std_before_detoxification}]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform Fine-tuning to Detoxify the summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init PPOTrainer\n",
    "learning_rate=1.41e-5\n",
    "max_ppo_epochs=5\n",
    "mini_batch_size=4\n",
    "batch_size=16\n",
    "\n",
    "config = PPOConfig(\n",
    "    model_name=model_name,\n",
    "    learning_rate=learning_rate,\n",
    "    ppo_epochs=max_ppo_epochs,\n",
    "    mini_batch_size=mini_batch_size,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "\n",
    "def collator(data):\n",
    "    return dict((key, [d[key] for d in data]) for key in data[0])\n",
    "\n",
    "ppo_trainer = PPOTrainer(config=config, \n",
    "                         model=ppo_model,\n",
    "                         ref_model=ref_model,\n",
    "                         tokenizer=tokenizer,\n",
    "                         dataset=dataset['train'],\n",
    "                         data_collator=collator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tune the model using RLHF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "1it [00:16, 16.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 30.14926528930664\n",
      "ppo/returns/mean: -0.7324256300926208\n",
      "ppo/policy/advantages_mean: 9.761287333986957e-10\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:28, 13.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 25.74405288696289\n",
      "ppo/returns/mean: -0.6467403173446655\n",
      "ppo/policy/advantages_mean: -1.1885238349051974e-09\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:39, 12.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 18.96527862548828\n",
      "ppo/returns/mean: -0.27608832716941833\n",
      "ppo/policy/advantages_mean: 2.396524312331394e-09\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:50, 11.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 15.906065940856934\n",
      "ppo/returns/mean: 0.05636598542332649\n",
      "ppo/policy/advantages_mean: -2.8726185874461407e-09\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [01:01, 11.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 20.988178253173828\n",
      "ppo/returns/mean: -0.2991626262664795\n",
      "ppo/policy/advantages_mean: -3.004546389462348e-09\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [01:11, 11.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 16.159339904785156\n",
      "ppo/returns/mean: 0.18312254548072815\n",
      "ppo/policy/advantages_mean: -1.1994056414721399e-08\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/net/papilio/storage6/phusaeng/anaconda3/envs/pytorch2/lib/python3.10/site-packages/transformers/pipelines/base.py:1081: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "7it [01:21, 10.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 15.339092254638672\n",
      "ppo/returns/mean: 0.07548432052135468\n",
      "ppo/policy/advantages_mean: -2.7277082814691767e-09\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [01:31, 10.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 17.691499710083008\n",
      "ppo/returns/mean: 0.008339645341038704\n",
      "ppo/policy/advantages_mean: -1.619415379572331e-09\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [01:40,  9.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 12.772361755371094\n",
      "ppo/returns/mean: 0.4266948699951172\n",
      "ppo/policy/advantages_mean: -1.4454728969326425e-08\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [01:48, 10.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 12.81867504119873\n",
      "ppo/returns/mean: 0.5007023215293884\n",
      "ppo/policy/advantages_mean: 3.1157996183139858e-09\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "output_min_length = 100\n",
    "output_max_length = 400\n",
    "output_length_sampler = LengthSampler(output_min_length, output_max_length)\n",
    "\n",
    "generation_kwargs = {\n",
    "    \"min_length\": 5,\n",
    "    \"top_k\":0.0,\n",
    "    \"top_p\":1.0,\n",
    "    \"do_sample\":True,\n",
    "}\n",
    "reward_kwargs = {\n",
    "    \"top_k\": None, # return all scores\n",
    "    \"function_to_apply\": \"none\", # we want the raw logits without softmax\n",
    "    \"batch_size\": 16\n",
    "}\n",
    "\n",
    "max_ppo_steps = 10\n",
    "for step, batch in tqdm(enumerate(ppo_trainer.dataloader)):\n",
    "    # Break when you reach max_steps.\n",
    "    if step >= max_ppo_steps:\n",
    "        break   \n",
    "\n",
    "    prompt_tensors = batch[\"input_ids\"]\n",
    "\n",
    "    # Get response from FLAN-T5/PEFT LLM.\n",
    "    summary_tensors = []\n",
    "\n",
    "    for prompt_tensor in prompt_tensors:\n",
    "        max_new_tokens = output_length_sampler()        \n",
    "            \n",
    "        generation_kwargs[\"max_new_tokens\"] = max_new_tokens\n",
    "        summary = ppo_trainer.generate(prompt_tensor, **generation_kwargs)\n",
    "        \n",
    "        summary_tensors.append(summary.squeeze()[-max_new_tokens:])\n",
    "        \n",
    "    # This needs to be called \"response\".\n",
    "    batch[\"response\"] = [tokenizer.decode(r.squeeze()) for r in summary_tensors]\n",
    "\n",
    "    # Compute reward outputs.\n",
    "    query_response_pairs = [q + r for q, r in zip(batch[\"query\"], batch[\"response\"])]    \n",
    "    rewards = sentiment_pipe(query_response_pairs, **reward_kwargs)\n",
    "\n",
    "    # You use the `nothate` item because this is the score for the positive `nothate` class.\n",
    "    reward_tensors = [torch.tensor(reward[not_hate_index][\"score\"]) for reward in rewards]    \n",
    "\n",
    "    # Run PPO step.\n",
    "    stats = ppo_trainer.step(prompt_tensors, summary_tensors, reward_tensors)\n",
    "    ppo_trainer.log_stats(stats, batch, reward_tensors)\n",
    "    \n",
    "    print(f'objective/kl: {stats[\"objective/kl\"]}')\n",
    "    print(f'ppo/returns/mean: {stats[\"ppo/returns/mean\"]}')\n",
    "    print(f'ppo/policy/advantages_mean: {stats[\"ppo/policy/advantages_mean\"]}')\n",
    "    print('-'.join('' for x in range(100)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the model qualitatively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:22<00:00,  1.14s/it]\n",
      "/net/papilio/storage6/phusaeng/anaconda3/envs/pytorch2/lib/python3.10/site-packages/transformers/pipelines/base.py:1081: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "batch_size = 20\n",
    "compare_results = {}\n",
    "df_batch = dataset['test'][0:batch_size]\n",
    "\n",
    "compare_results['query'] = df_batch['query']\n",
    "prompt_tensors = df_batch['input_ids']\n",
    "\n",
    "summary_tensors_ref = []\n",
    "summary_tensors = []\n",
    "\n",
    "# Get response from ppo and base model\n",
    "for i in tqdm(range(batch_size)):\n",
    "    gen_len = output_length_sampler()\n",
    "    generation_kwargs['max_new_tokens'] = gen_len\n",
    "\n",
    "    summary = ref_model.generate( \n",
    "        input_ids=torch.as_tensor(prompt_tensors[i]).unsqueeze(dim=0).to(device),\n",
    "        **generation_kwargs\n",
    "    ).squeeze()[-gen_len:]\n",
    "    summary_tensors_ref.append(summary)\n",
    "\n",
    "    summary = ppo_model.generate(\n",
    "        input_ids=torch.as_tensor(prompt_tensors[i]).unsqueeze(dim=0).to(device),\n",
    "        **generation_kwargs\n",
    "    ).squeeze()[-gen_len:]\n",
    "    summary_tensors.append(summary)\n",
    "\n",
    "# decode response\n",
    "compare_results['response_before'] = [tokenizer.decode(summary_tensors_ref[i]) for i in range(batch_size)]\n",
    "compare_results['response_after'] = [tokenizer.decode(summary_tensors[i]) for i in range(batch_size)]\n",
    "\n",
    "# Sentiment analysis of query/response pairs before/after\n",
    "texts_before = [d+s for d, s in zip(compare_results['query'], compare_results['response_before'])]\n",
    "rewards_before = sentiment_pipe(texts_before, **reward_kwargs)\n",
    "compare_results['reward_before'] = [reward[not_hate_index]['score'] for reward in rewards_before]\n",
    "\n",
    "texts_after = [d+s for d, s in zip(compare_results['query'], compare_results['response_after'])]\n",
    "rewards_after = sentiment_pipe(texts_after, **reward_kwargs)\n",
    "compare_results['reward_after'] = [reward[not_hate_index]['score'] for reward in rewards_after]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['query', 'response_before', 'response_after', 'reward_before', 'reward_after'])"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>response_before</th>\n",
       "      <th>response_after</th>\n",
       "      <th>reward_before</th>\n",
       "      <th>reward_after</th>\n",
       "      <th>reward_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Summarize the following conversation. #Person1#: Mom, I just finished my paper. Can you proofread it before I hand it in? #Person2#: Sure, let's take a look. Sweetie, this is terrific. Your ideas are so original. #Person1#: Thanks. #Person2#: I can tell you worked hard on it. #Person1#: I really did! I started thinking about what I wanted to say three weeks ago. #Person2#: Well, it was definitely worth all the time. #Person1#: Let's just hope my teacher agrees. Summary: &lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; #Person1# proofread the paper and keep #Person2# thinking about it. #Person1# shouts it's excellent but #Person1# hopes it's worth the time to ask \"My teacher\" to agree.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; Mom suggested that #Person1# read a paper that is terrific and work on it.&lt;/s&gt;</td>\n",
       "      <td>1.850283</td>\n",
       "      <td>2.806221</td>\n",
       "      <td>0.955938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Summarize the following conversation. #Person1#: I'd like to have this cashed, please. #Person2#: Please put you name and address here. May I see your passport? #Person1#: Yes. #Person2#: How would you like it? #Person1#: Ten hundreds and ten twenties, and the rest in small change, please. #Person2#: OK. Here you are. Summary: &lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; #Person1# needs to get a handcash cashed. #Person2# tells #Person1# how many bills she wants in the appearance of your passport, and the rest of the sum in small change.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; #Person1# looks after the chip.&lt;/s&gt;</td>\n",
       "      <td>1.217562</td>\n",
       "      <td>2.084290</td>\n",
       "      <td>0.866728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Summarize the following conversation. #Person1#: How much are you asking for this? #Person2#: I'm offering them to you at 150 yuan a piece. Is that all right? #Person1#: Is tax already included in their price? #Person2#: Yes. Our price can't be matched. #Person1#: Would you consider a volume discount? #Person2#: If you buy 1, 000 or more, you'll get a 10 % discount. #Person1#: I'll accept your offer. Summary: &lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; #Person1#'ll give 5 90 yuan for 150 yuan a piece of pizza for 150 Yuan and add 10 % discount.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; #Person1# will buy a 150 yuan piece of bread at 150 yuan a piece.&lt;/s&gt;</td>\n",
       "      <td>2.520337</td>\n",
       "      <td>2.954733</td>\n",
       "      <td>0.434396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Summarize the following conversation. #Person1#: Today more and more families have personal computers. People have wider range of choice to communicate with the outside world. #Person2#: Right. With the establishment of Internet and a lot of web companies, people are getting more and more dependent on the web. #Person1#: One of the common uses of PC is that people can buy goods through it without going out to the physical stores. #Person2#: Can you tell me how it is done? #Person1#: If a cus...</td>\n",
       "      <td>&lt;pad&gt; #Person1# tells #Person2# how PC is helping people buy goods through it and they prefer paying for things online.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; People have wider range of choice to communicate with the outside world with computer.&lt;/s&gt;</td>\n",
       "      <td>2.459565</td>\n",
       "      <td>2.718758</td>\n",
       "      <td>0.259193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Summarize the following conversation. #Person1#: It smells like an ashtray in here! #Person2#: Hi honey! What's wrong? Why do you have that look on your face? #Person1#: What's wrong? I thought we agreed that you were gonna quit smoking. #Person2#: No! I said I was going to cut down which is very different. You can't just expect me to go cold turkey overnight! #Person1#: Look, there are other ways to quit. You can try the nicotine patch, or nicotine chewing gum. We spend a fortune on cigaret...</td>\n",
       "      <td>&lt;pad&gt; Honey seems to light up his smokes constantly. Honey doesn't have the willpower to quit. Instead one thing she tries is the nicotine patch, or nicotine chewing gum. Honey finds it helpful but will have a divorce.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; Honey is thinking it would be hard to quit smoking, because of the laws cracking down. It doesn't give her the willpower.&lt;/s&gt;</td>\n",
       "      <td>1.494994</td>\n",
       "      <td>1.678974</td>\n",
       "      <td>0.183980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Summarize the following conversation. #Person1#: Let's take a coffee break, shall we? #Person2#: I wish I could, but I can't. #Person1#: What keeps you so busy? You've been sitting there for hours. You've got to walk around. You just can't stay on the computer forever. #Person2#: Well, I am up to my neck in work. I've got to finish this report. Sarah needs it by noon. I don't want to be scolded if I can't finish my work by the deadline. #Person1#: I understand that, but you'd feel better if ...</td>\n",
       "      <td>&lt;pad&gt; Sarah needs the report by noon today and she wants the time to finish it because #Person1# is too busy to concentrate and is sedentary.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; Sarah needs up to a 45 minutes to finish her work. #Person1# asks Sarah to take a coffee break.&lt;/s&gt;</td>\n",
       "      <td>1.957293</td>\n",
       "      <td>2.100831</td>\n",
       "      <td>0.143538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Summarize the following conversation. #Person1#: Where shall I register, please? #Person2#: Here. Do you have a registration card? #Person1#: Yes. Here you are. #Person2#: Please register your information here and pay for it. And I'll make a medical record for you. #Person1#: OK. How much do I need to pay for the registration? #Person2#: Please pay ten yuan for the registration. #Person1#: Here is my money. #Person2#: This is your registration card. Please don't lose it and bring it whenever...</td>\n",
       "      <td>&lt;pad&gt; #Person1# will register into the clinic but #Person2# will make a medical record for her doesn't know how to get to the Cofei room.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; #Person1# wants to register for the appointment of a professional's computer. The tiny computer is too big to be turned around by the pharmacist or consultant and the computer is pretty useless.&lt;/s&gt;</td>\n",
       "      <td>1.342309</td>\n",
       "      <td>1.431467</td>\n",
       "      <td>0.089158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Summarize the following conversation. #Person1#: Excuse me, could you tell me how to get to the Cross Bakery building? #Person2#: The Cross Bakery building? Oh sure. You're actually walking in the opposite direction. #Person1#: Oh, you're kidding! I thought I was heading east. #Person2#: No, east is the other direction. To get to the Bakery, you need to turn around and go three blocks to Broadway. When you get to the intersection of Broadway and Elm, you hang a left. Go straight down that st...</td>\n",
       "      <td>&lt;pad&gt; #Person2#'s telling #Person1# how to get to the Cross Bakery building. #Person2# asks #Person1# to show him how to get to the Cross Bakery building.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; #Person1# asks for directions to cross bakery. The person asks how to get there.&lt;/s&gt;</td>\n",
       "      <td>2.677873</td>\n",
       "      <td>2.719361</td>\n",
       "      <td>0.041488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Summarize the following conversation. #Person1#: What can I do for you, madam? #Person2#: I'd like to buy a toy car for my son. #Person1#: How about this one? #Person2#: It looks nice. How much is it? #Person1#: They're three hundred dollars. #Person2#: Oh, I'm afraid it's too expensive. Can you show me something cheaper? #Person1#: OK, This one is one hundred and twenty. It's the cheapest here. #Person2#: OK, I'll take it. Here's the money. #Person1#: Thank you very much. Summary: &lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; #Person2# wants to buy a toy car for his son. According to #Person1#, the biggest one is one hundred and twenty dollars. But #Person2# is surprised by the lowest one, but #Person1# agrees.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; #Person1# wants to buy a toy car.&lt;/s&gt;</td>\n",
       "      <td>1.342674</td>\n",
       "      <td>1.381266</td>\n",
       "      <td>0.038592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Summarize the following conversation. #Person1#: I would like to order some internet today. #Person2#: What kind would you like? #Person1#: What kind of internet is there? #Person2#: You can get DEL or dial-up. #Person1#: Which of those two is best? #Person2#: I would recommend DEL. #Person1#: So that one better? #Person2#: It's better because it doesn't tie up the phone. #Person1#: What do you mean by that? #Person2#: DEL isn't connected through your phone line, but dial-up is. #Person1#: S...</td>\n",
       "      <td>&lt;pad&gt; #Person1# believes they should buy DEL instead of dial-up internet because #Person1# thinks they can't use their phone because of DEL.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; #Person1# is buying internet for the first time, but she doesn't want to use her phone when it's on the Internet.&lt;/s&gt;</td>\n",
       "      <td>1.968518</td>\n",
       "      <td>1.902239</td>\n",
       "      <td>-0.066279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Summarize the following conversation. #Person1#: So how did you like the restaurant? #Person2#: Actually, it could have been better. #Person1#: What didn't you like about it? #Person2#: It is a new restaurant. I don't think they have their act together yet. #Person1#: What did you think about the food? #Person2#: I felt that the food was pretty mediocre. #Person1#: The service wasn't that great, either. #Person2#: I agree. The service was not good. #Person1#: Do you think that you want to tr...</td>\n",
       "      <td>&lt;pad&gt; #Person1# wants to try the restaurant but he doesn't want to try it because of the staff and the restaurant's only act.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; Nick and his wife think that the restaurant is a new one and they don't think they have their act together yet.&lt;/s&gt;</td>\n",
       "      <td>2.229713</td>\n",
       "      <td>2.159089</td>\n",
       "      <td>-0.070625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Summarize the following conversation. #Person1#: Hello. I want to reconfirm our flight to London. #Person2#: Yes, sir. Did you call the airline? #Person1#: Yes, I did. But I couldn't communicate with them in English. They speak only Spanish. So I need your help. #Person2#: Certainly, sir. What is the flight number and when are you leaving? #Person1#: We are taking IB 385 to London tomorrow at 1 p. m. #Person2#: Oh, I see, sir. We have the airline office inside the hotel. They have an English...</td>\n",
       "      <td>&lt;pad&gt; #Person1# wants to confirm their flight from London to London to fly IB 385 tomorrow at 1 p.m. They call the airline office and catch the backoffice, and the airline office has English speaking staff.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; #Person1# wants to reconfirm their flight to London to London early at 1 p.m. After a few minutes, they dial IB 385.&lt;/s&gt;</td>\n",
       "      <td>2.020423</td>\n",
       "      <td>1.871109</td>\n",
       "      <td>-0.149314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Summarize the following conversation. #Person1#: I'm forming a music band. #Person2#: Do you already know how to play an instrument? #Person1#: Uh... Yeah! I'Ve told you a thousand times that I'm learning to play the drums. Now that I know how to play well, I would like to form a rock band. #Person2#: Aside from yourself, who are the other members of the band? #Person1#: We have a guy who plays guitar, and another who plays bass. Although we still haven't found anyone to be our singer. You t...</td>\n",
       "      <td>&lt;pad&gt; #Person1# wants to form a music band. He wants to fill in the band with some singers who can audition at #Person1#'s house. He will audition a few times, but has little space for other performances.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; #Person1#'s goodahead to form a music band. Number 1# wanted to perform and is looking for singers.&lt;/s&gt;</td>\n",
       "      <td>2.607203</td>\n",
       "      <td>2.444721</td>\n",
       "      <td>-0.162483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Summarize the following conversation. #Person1#: Here is the final draft of our contract. I'm glad that we have reached an agreement on almost every term in our trade. #Person2#: Yes, it seems to me we have come quite a long way. However, let me take a close look at the final draft. #Person1#: Do you have some points to bring up? #Person2#: Well, everything we've discussed seems to be here. #Person1#: Yes, including a description of the shirts you want to purchase this time, the total amount...</td>\n",
       "      <td>&lt;pad&gt; #Person1# presents the final draft of an agreement and tells #Person2# some points to bring up. #Person2# asks him to take a close look at the final draft.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; #Person1# tells #Person2# the final draft of the contract.&lt;/s&gt;</td>\n",
       "      <td>2.926492</td>\n",
       "      <td>2.751378</td>\n",
       "      <td>-0.175115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Summarize the following conversation. #Person1#: Amanda, how do you like this peaked cap? #Person2#: Didn't you say you want to buy a top hat? #Person1#: But I think this one fits me Well. Why don't you try on the sombrero in black? #Person2#: I don't like caps at all. Summary: &lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; Amandas wanted to buy a top hat but don't like it because Amanda wants a peaked cap. Amanda doesn't like caps at all.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; Amanda prefers the peaked cap. She doesn't like the top hat.&lt;/s&gt;</td>\n",
       "      <td>1.056981</td>\n",
       "      <td>0.848894</td>\n",
       "      <td>-0.208086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Summarize the following conversation. #Person1#: Oh, my God! What's this? #Person2#: What? #Person1#: Look! This window is open. #Person2#: Did you open it before we left? #Person1#: Are you kidding? It's winter. Why would I open it? #Person2#: I don't know. Wait. Is this yours? #Person1#: No! Oh, my God! Someone has broken into the house. #Person2#: It looks that way. That's probably why the door wasn't locked when we came in. #Person1#: I locked it when I left though. #Person2#: Yes, but t...</td>\n",
       "      <td>&lt;pad&gt; Allen thinks someone broke in the house but doesn't believe he robbed himself. Allen insists about searching, but he's reluctant.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; Allen informs Allen that he's robbed. Allen also tells him that the entire images of the house were stolen by the robber.&lt;/s&gt;</td>\n",
       "      <td>2.346088</td>\n",
       "      <td>2.013045</td>\n",
       "      <td>-0.333043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Summarize the following conversation. #Person1#: Hello? #Person2#: Hello? #Person1#: Can I speak to Li Hong, please? #Person2#: Speaking. #Person1#: Hi, Li Hong. This is Alice. #Person2#: Hi, Alice. How are you? #Person1#: Not bad. Li Hong, I am sorry that I can't go to see Mrs. Brown with you tomorrow morning. My mother is ill. I must take care of her. #Person2#: I'm sorry to hear that. You'd better stay at home. After all, we can visit Mrs. Brown later #Person1#: OK. Bye - bye. #Person2#: ...</td>\n",
       "      <td>&lt;pad&gt; Alice could not go to see Mrs. Brown with #Person1# tomorrow morning, because her mother is ill. Alice urged #Person2# not to go out to the meeting. Alice advises her to stay at home.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; Alice will not go to Mrs. Brown tomorrow morning. Li Hong tells Alice that her mother is sick.&lt;/s&gt;</td>\n",
       "      <td>1.462162</td>\n",
       "      <td>1.019700</td>\n",
       "      <td>-0.442461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Summarize the following conversation. #Person1#: Could you help me figure out how to look for a job? #Person2#: We have lots of options, what type of job do you need? #Person1#: I want to work in an office. #Person2#: Do you want to work part-time or full-time? #Person1#: I want to work full-time. #Person2#: We have binders with local job listings or you can make use of the computers. OK? #Person1#: I am confused a bit but I am sure that I can figure it out. #Person2#: If you make an appoint...</td>\n",
       "      <td>&lt;pad&gt; #Person1# tells #Person2# about a job to work full-time in an office. ‘Person1# wants to work in an office. #Person1# informs #Person1# about working with binders and computers and this job center is here to help.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; #Person1# wants to work in an office.&lt;/s&gt;</td>\n",
       "      <td>2.492378</td>\n",
       "      <td>1.983008</td>\n",
       "      <td>-0.509370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Summarize the following conversation. #Person1#: Judy, what is everybody talking about? #Person2#: Haven't you heard? Richard was fired by our manager. #Person1#: You're kidding. It can't be true. #Person2#: Believe it or not. Everybody is talking about it in the company. #Person1#: Really? I'm surprised. #Person2#: Me too. Summary: &lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; John is surprised with the results of Richard's fired by his manager. Judy and #Person1# are very surprised.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; Richard was fired by her manager. Judy and #Person2# are surprised.&lt;/s&gt;</td>\n",
       "      <td>1.848298</td>\n",
       "      <td>1.240198</td>\n",
       "      <td>-0.608100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Summarize the following conversation. #Person1#: Could you help me, Sir? My flight got in 15 minutes ago. Everyone else has picked up the luggage but mine hasn't come through. #Person2#: I'm sorry, Madam, I'll go and find out if there is any more to come. Summary: &lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; No one used to talk to #Person1# because his flight got in the 15 minutes earlier but #Person1# did not get through. He let them know he was sorry.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; #Person1# is madman and frankly's flight has gotten in 15 minutes. He asks about the flight now and will come back only if there is more to come.&lt;/s&gt;</td>\n",
       "      <td>2.368266</td>\n",
       "      <td>0.974238</td>\n",
       "      <td>-1.394028</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  query   \n",
       "0                       Summarize the following conversation. #Person1#: Mom, I just finished my paper. Can you proofread it before I hand it in? #Person2#: Sure, let's take a look. Sweetie, this is terrific. Your ideas are so original. #Person1#: Thanks. #Person2#: I can tell you worked hard on it. #Person1#: I really did! I started thinking about what I wanted to say three weeks ago. #Person2#: Well, it was definitely worth all the time. #Person1#: Let's just hope my teacher agrees. Summary: </s>  \\\n",
       "1                                                                                                                                                                         Summarize the following conversation. #Person1#: I'd like to have this cashed, please. #Person2#: Please put you name and address here. May I see your passport? #Person1#: Yes. #Person2#: How would you like it? #Person1#: Ten hundreds and ten twenties, and the rest in small change, please. #Person2#: OK. Here you are. Summary: </s>   \n",
       "2                                                                                     Summarize the following conversation. #Person1#: How much are you asking for this? #Person2#: I'm offering them to you at 150 yuan a piece. Is that all right? #Person1#: Is tax already included in their price? #Person2#: Yes. Our price can't be matched. #Person1#: Would you consider a volume discount? #Person2#: If you buy 1, 000 or more, you'll get a 10 % discount. #Person1#: I'll accept your offer. Summary: </s>   \n",
       "3   Summarize the following conversation. #Person1#: Today more and more families have personal computers. People have wider range of choice to communicate with the outside world. #Person2#: Right. With the establishment of Internet and a lot of web companies, people are getting more and more dependent on the web. #Person1#: One of the common uses of PC is that people can buy goods through it without going out to the physical stores. #Person2#: Can you tell me how it is done? #Person1#: If a cus...   \n",
       "4   Summarize the following conversation. #Person1#: It smells like an ashtray in here! #Person2#: Hi honey! What's wrong? Why do you have that look on your face? #Person1#: What's wrong? I thought we agreed that you were gonna quit smoking. #Person2#: No! I said I was going to cut down which is very different. You can't just expect me to go cold turkey overnight! #Person1#: Look, there are other ways to quit. You can try the nicotine patch, or nicotine chewing gum. We spend a fortune on cigaret...   \n",
       "5   Summarize the following conversation. #Person1#: Let's take a coffee break, shall we? #Person2#: I wish I could, but I can't. #Person1#: What keeps you so busy? You've been sitting there for hours. You've got to walk around. You just can't stay on the computer forever. #Person2#: Well, I am up to my neck in work. I've got to finish this report. Sarah needs it by noon. I don't want to be scolded if I can't finish my work by the deadline. #Person1#: I understand that, but you'd feel better if ...   \n",
       "6   Summarize the following conversation. #Person1#: Where shall I register, please? #Person2#: Here. Do you have a registration card? #Person1#: Yes. Here you are. #Person2#: Please register your information here and pay for it. And I'll make a medical record for you. #Person1#: OK. How much do I need to pay for the registration? #Person2#: Please pay ten yuan for the registration. #Person1#: Here is my money. #Person2#: This is your registration card. Please don't lose it and bring it whenever...   \n",
       "7   Summarize the following conversation. #Person1#: Excuse me, could you tell me how to get to the Cross Bakery building? #Person2#: The Cross Bakery building? Oh sure. You're actually walking in the opposite direction. #Person1#: Oh, you're kidding! I thought I was heading east. #Person2#: No, east is the other direction. To get to the Bakery, you need to turn around and go three blocks to Broadway. When you get to the intersection of Broadway and Elm, you hang a left. Go straight down that st...   \n",
       "8           Summarize the following conversation. #Person1#: What can I do for you, madam? #Person2#: I'd like to buy a toy car for my son. #Person1#: How about this one? #Person2#: It looks nice. How much is it? #Person1#: They're three hundred dollars. #Person2#: Oh, I'm afraid it's too expensive. Can you show me something cheaper? #Person1#: OK, This one is one hundred and twenty. It's the cheapest here. #Person2#: OK, I'll take it. Here's the money. #Person1#: Thank you very much. Summary: </s>   \n",
       "9   Summarize the following conversation. #Person1#: I would like to order some internet today. #Person2#: What kind would you like? #Person1#: What kind of internet is there? #Person2#: You can get DEL or dial-up. #Person1#: Which of those two is best? #Person2#: I would recommend DEL. #Person1#: So that one better? #Person2#: It's better because it doesn't tie up the phone. #Person1#: What do you mean by that? #Person2#: DEL isn't connected through your phone line, but dial-up is. #Person1#: S...   \n",
       "10  Summarize the following conversation. #Person1#: So how did you like the restaurant? #Person2#: Actually, it could have been better. #Person1#: What didn't you like about it? #Person2#: It is a new restaurant. I don't think they have their act together yet. #Person1#: What did you think about the food? #Person2#: I felt that the food was pretty mediocre. #Person1#: The service wasn't that great, either. #Person2#: I agree. The service was not good. #Person1#: Do you think that you want to tr...   \n",
       "11  Summarize the following conversation. #Person1#: Hello. I want to reconfirm our flight to London. #Person2#: Yes, sir. Did you call the airline? #Person1#: Yes, I did. But I couldn't communicate with them in English. They speak only Spanish. So I need your help. #Person2#: Certainly, sir. What is the flight number and when are you leaving? #Person1#: We are taking IB 385 to London tomorrow at 1 p. m. #Person2#: Oh, I see, sir. We have the airline office inside the hotel. They have an English...   \n",
       "12  Summarize the following conversation. #Person1#: I'm forming a music band. #Person2#: Do you already know how to play an instrument? #Person1#: Uh... Yeah! I'Ve told you a thousand times that I'm learning to play the drums. Now that I know how to play well, I would like to form a rock band. #Person2#: Aside from yourself, who are the other members of the band? #Person1#: We have a guy who plays guitar, and another who plays bass. Although we still haven't found anyone to be our singer. You t...   \n",
       "13  Summarize the following conversation. #Person1#: Here is the final draft of our contract. I'm glad that we have reached an agreement on almost every term in our trade. #Person2#: Yes, it seems to me we have come quite a long way. However, let me take a close look at the final draft. #Person1#: Do you have some points to bring up? #Person2#: Well, everything we've discussed seems to be here. #Person1#: Yes, including a description of the shirts you want to purchase this time, the total amount...   \n",
       "14                                                                                                                                                                                                                          Summarize the following conversation. #Person1#: Amanda, how do you like this peaked cap? #Person2#: Didn't you say you want to buy a top hat? #Person1#: But I think this one fits me Well. Why don't you try on the sombrero in black? #Person2#: I don't like caps at all. Summary: </s>   \n",
       "15  Summarize the following conversation. #Person1#: Oh, my God! What's this? #Person2#: What? #Person1#: Look! This window is open. #Person2#: Did you open it before we left? #Person1#: Are you kidding? It's winter. Why would I open it? #Person2#: I don't know. Wait. Is this yours? #Person1#: No! Oh, my God! Someone has broken into the house. #Person2#: It looks that way. That's probably why the door wasn't locked when we came in. #Person1#: I locked it when I left though. #Person2#: Yes, but t...   \n",
       "16  Summarize the following conversation. #Person1#: Hello? #Person2#: Hello? #Person1#: Can I speak to Li Hong, please? #Person2#: Speaking. #Person1#: Hi, Li Hong. This is Alice. #Person2#: Hi, Alice. How are you? #Person1#: Not bad. Li Hong, I am sorry that I can't go to see Mrs. Brown with you tomorrow morning. My mother is ill. I must take care of her. #Person2#: I'm sorry to hear that. You'd better stay at home. After all, we can visit Mrs. Brown later #Person1#: OK. Bye - bye. #Person2#: ...   \n",
       "17  Summarize the following conversation. #Person1#: Could you help me figure out how to look for a job? #Person2#: We have lots of options, what type of job do you need? #Person1#: I want to work in an office. #Person2#: Do you want to work part-time or full-time? #Person1#: I want to work full-time. #Person2#: We have binders with local job listings or you can make use of the computers. OK? #Person1#: I am confused a bit but I am sure that I can figure it out. #Person2#: If you make an appoint...   \n",
       "18                                                                                                                                                                  Summarize the following conversation. #Person1#: Judy, what is everybody talking about? #Person2#: Haven't you heard? Richard was fired by our manager. #Person1#: You're kidding. It can't be true. #Person2#: Believe it or not. Everybody is talking about it in the company. #Person1#: Really? I'm surprised. #Person2#: Me too. Summary: </s>   \n",
       "19                                                                                                                                                                                                                                        Summarize the following conversation. #Person1#: Could you help me, Sir? My flight got in 15 minutes ago. Everyone else has picked up the luggage but mine hasn't come through. #Person2#: I'm sorry, Madam, I'll go and find out if there is any more to come. Summary: </s>   \n",
       "\n",
       "                                                                                                                                                                                                                    response_before   \n",
       "0                                               <pad> #Person1# proofread the paper and keep #Person2# thinking about it. #Person1# shouts it's excellent but #Person1# hopes it's worth the time to ask \"My teacher\" to agree.</s>  \\\n",
       "1                                               <pad> #Person1# needs to get a handcash cashed. #Person2# tells #Person1# how many bills she wants in the appearance of your passport, and the rest of the sum in small change.</s>   \n",
       "2                                                                                                                           <pad> #Person1#'ll give 5 90 yuan for 150 yuan a piece of pizza for 150 Yuan and add 10 % discount.</s>   \n",
       "3                                                                                                       <pad> #Person1# tells #Person2# how PC is helping people buy goods through it and they prefer paying for things online.</s>   \n",
       "4    <pad> Honey seems to light up his smokes constantly. Honey doesn't have the willpower to quit. Instead one thing she tries is the nicotine patch, or nicotine chewing gum. Honey finds it helpful but will have a divorce.</s>   \n",
       "5                                                                                 <pad> Sarah needs the report by noon today and she wants the time to finish it because #Person1# is too busy to concentrate and is sedentary.</s>   \n",
       "6                                                                                     <pad> #Person1# will register into the clinic but #Person2# will make a medical record for her doesn't know how to get to the Cofei room.</s>   \n",
       "7                                                                    <pad> #Person2#'s telling #Person1# how to get to the Cross Bakery building. #Person2# asks #Person1# to show him how to get to the Cross Bakery building.</s>   \n",
       "8                            <pad> #Person2# wants to buy a toy car for his son. According to #Person1#, the biggest one is one hundred and twenty dollars. But #Person2# is surprised by the lowest one, but #Person1# agrees.</s>   \n",
       "9                                                                                  <pad> #Person1# believes they should buy DEL instead of dial-up internet because #Person1# thinks they can't use their phone because of DEL.</s>   \n",
       "10                                                                                                <pad> #Person1# wants to try the restaurant but he doesn't want to try it because of the staff and the restaurant's only act.</s>   \n",
       "11               <pad> #Person1# wants to confirm their flight from London to London to fly IB 385 tomorrow at 1 p.m. They call the airline office and catch the backoffice, and the airline office has English speaking staff.</s>   \n",
       "12                 <pad> #Person1# wants to form a music band. He wants to fill in the band with some singers who can audition at #Person1#'s house. He will audition a few times, but has little space for other performances.</s>   \n",
       "13                                                            <pad> #Person1# presents the final draft of an agreement and tells #Person2# some points to bring up. #Person2# asks him to take a close look at the final draft.</s>   \n",
       "14                                                                                                  <pad> Amandas wanted to buy a top hat but don't like it because Amanda wants a peaked cap. Amanda doesn't like caps at all.</s>   \n",
       "15                                                                                      <pad> Allen thinks someone broke in the house but doesn't believe he robbed himself. Allen insists about searching, but he's reluctant.</s>   \n",
       "16                                <pad> Alice could not go to see Mrs. Brown with #Person1# tomorrow morning, because her mother is ill. Alice urged #Person2# not to go out to the meeting. Alice advises her to stay at home.</s>   \n",
       "17  <pad> #Person1# tells #Person2# about a job to work full-time in an office. ‘Person1# wants to work in an office. #Person1# informs #Person1# about working with binders and computers and this job center is here to help.</s>   \n",
       "18                                                                                                           <pad> John is surprised with the results of Richard's fired by his manager. Judy and #Person1# are very surprised.</s>   \n",
       "19                                                                    <pad> No one used to talk to #Person1# because his flight got in the 15 minutes earlier but #Person1# did not get through. He let them know he was sorry.</s>   \n",
       "\n",
       "                                                                                                                                                                                                  response_after   \n",
       "0                                                                                                                           <pad> Mom suggested that #Person1# read a paper that is terrific and work on it.</s>  \\\n",
       "1                                                                                                                                                                      <pad> #Person1# looks after the chip.</s>   \n",
       "2                                                                                                                                    <pad> #Person1# will buy a 150 yuan piece of bread at 150 yuan a piece.</s>   \n",
       "3                                                                                                               <pad> People have wider range of choice to communicate with the outside world with computer.</s>   \n",
       "4                                                                            <pad> Honey is thinking it would be hard to quit smoking, because of the laws cracking down. It doesn't give her the willpower.</s>   \n",
       "5                                                                                                      <pad> Sarah needs up to a 45 minutes to finish her work. #Person1# asks Sarah to take a coffee break.</s>   \n",
       "6   <pad> #Person1# wants to register for the appointment of a professional's computer. The tiny computer is too big to be turned around by the pharmacist or consultant and the computer is pretty useless.</s>   \n",
       "7                                                                                                                     <pad> #Person1# asks for directions to cross bakery. The person asks how to get there.</s>   \n",
       "8                                                                                                                                                                    <pad> #Person1# wants to buy a toy car.</s>   \n",
       "9                                                                                    <pad> #Person1# is buying internet for the first time, but she doesn't want to use her phone when it's on the Internet.</s>   \n",
       "10                                                                                     <pad> Nick and his wife think that the restaurant is a new one and they don't think they have their act together yet.</s>   \n",
       "11                                                                                <pad> #Person1# wants to reconfirm their flight to London to London early at 1 p.m. After a few minutes, they dial IB 385.</s>   \n",
       "12                                                                                                 <pad> #Person1#'s goodahead to form a music band. Number 1# wanted to perform and is looking for singers.</s>   \n",
       "13                                                                                                                                          <pad> #Person1# tells #Person2# the final draft of the contract.</s>   \n",
       "14                                                                                                                                        <pad> Amanda prefers the peaked cap. She doesn't like the top hat.</s>   \n",
       "15                                                                           <pad> Allen informs Allen that he's robbed. Allen also tells him that the entire images of the house were stolen by the robber.</s>   \n",
       "16                                                                                                      <pad> Alice will not go to Mrs. Brown tomorrow morning. Li Hong tells Alice that her mother is sick.</s>   \n",
       "17                                                                                                                                                               <pad> #Person1# wants to work in an office.</s>   \n",
       "18                                                                                                                                 <pad> Richard was fired by her manager. Judy and #Person2# are surprised.</s>   \n",
       "19                                                   <pad> #Person1# is madman and frankly's flight has gotten in 15 minutes. He asks about the flight now and will come back only if there is more to come.</s>   \n",
       "\n",
       "    reward_before  reward_after  reward_diff  \n",
       "0        1.850283      2.806221     0.955938  \n",
       "1        1.217562      2.084290     0.866728  \n",
       "2        2.520337      2.954733     0.434396  \n",
       "3        2.459565      2.718758     0.259193  \n",
       "4        1.494994      1.678974     0.183980  \n",
       "5        1.957293      2.100831     0.143538  \n",
       "6        1.342309      1.431467     0.089158  \n",
       "7        2.677873      2.719361     0.041488  \n",
       "8        1.342674      1.381266     0.038592  \n",
       "9        1.968518      1.902239    -0.066279  \n",
       "10       2.229713      2.159089    -0.070625  \n",
       "11       2.020423      1.871109    -0.149314  \n",
       "12       2.607203      2.444721    -0.162483  \n",
       "13       2.926492      2.751378    -0.175115  \n",
       "14       1.056981      0.848894    -0.208086  \n",
       "15       2.346088      2.013045    -0.333043  \n",
       "16       1.462162      1.019700    -0.442461  \n",
       "17       2.492378      1.983008    -0.509370  \n",
       "18       1.848298      1.240198    -0.608100  \n",
       "19       2.368266      0.974238    -1.394028  "
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', 500)\n",
    "df_compare_results = pd.DataFrame(compare_results)\n",
    "df_compare_results['reward_diff'] = df_compare_results['reward_after'] - df_compare_results['reward_before']\n",
    "df_compare_results_sorted = df_compare_results.sort_values(by=['reward_diff'], ascending=False).reset_index(drop=True)\n",
    "df_compare_results_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5]"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[1, 2, 3 ,4 ,5][-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch2",
   "language": "python",
   "name": "pytorch2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
